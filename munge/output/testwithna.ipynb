{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import luigi\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from luigi.contrib import postgres\n",
    "from luigi.contrib import rdbms\n",
    "import subprocess\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import os\n",
    "from time import time\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "# from __future__ import division\n",
    "sqluser = 'postgres'\n",
    "sourcedb = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "pw = 'postgres'\n",
    "targetdb = 'munge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con=psycopg2.connect(user=sqluser,\n",
    "                     password=pw,\n",
    "                     host='/var/run/postgresql/',\n",
    "                     dbname=targetdb)\n",
    "con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Train and Test Data\n",
    "\n",
    "#feature list\n",
    "fco_list = pd.read_sql(\"select distinct feature from featureset_a where chart like any(values('chartevents'),('outputevents'))\",\n",
    "                       con)['feature'].tolist()\n",
    "fl_list = pd.read_sql(\"select distinct feature from featureset_a where chart like 'labevents'\"\n",
    "                      , con)['feature'].tolist()\n",
    "fco_list.remove(\"ignore\") \n",
    "fl_list.remove(\"ignore\")\n",
    "\n",
    "#import context\n",
    "real_train = pd.read_sql('select * from train_context;',con)\n",
    "real_test = pd.read_sql('select * from test_context;',con)\n",
    "\n",
    "#import timebucket and daybucket\n",
    "ss = ''\n",
    "for f in fco_list:\n",
    "    ss += 'avg({0}) as {0}, '.format(f)\n",
    "ss = ss[:-2]\n",
    "\n",
    "tt = ''\n",
    "for t in fl_list:\n",
    "    tt += 'avg({0}) as {0}, '.format(t)\n",
    "tt = tt[:-2]\n",
    "\n",
    "uu = ''\n",
    "for f in fco_list:\n",
    "    uu += 'avg({0}) as {0}, '.format(f)\n",
    "uu = uu[:-2]\n",
    "\n",
    "vv = ''\n",
    "for t in fl_list:\n",
    "    vv += 'avg({0}) as {0}, '.format(t)\n",
    "vv = vv[:-2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_real_1_train = pd.read_sql('select icustay_id, {0} from train_timebucket group by icustay_id;'.format(ss),con)\n",
    "avg_real_2_train = pd.read_sql('select hadm_id, {0} from train_daybucket group by hadm_id;'.format(tt),con)\n",
    "avg_real_1_test = pd.read_sql('select icustay_id, {0} from test_timebucket group by icustay_id;'.format(ss),con)\n",
    "avg_real_2_test = pd.read_sql('select hadm_id, {0} from test_daybucket group by hadm_id;'.format(tt),con)\n",
    "\n",
    "realdf_train = real_train.merge(avg_real_1_train, how='inner', on='icustay_id')\n",
    "realdf_train = realdf_train.merge(avg_real_2_train, how='inner', on='hadm_id')\n",
    "realdf_train['gcs_e'] = realdf_train['gcs_e'].fillna(4)\n",
    "realdf_train['gcs_v'] = realdf_train['gcs_v'].fillna(5)\n",
    "realdf_train['gcs_m'] = realdf_train['gcs_m'].fillna(6)\n",
    "realdf_train['gcs_total'] = realdf_train.gcs_e+realdf_train.gcs_m+realdf_train.gcs_v\n",
    "\n",
    "realdf_test = real_test.merge(avg_real_1_test, how='inner', on='icustay_id')\n",
    "realdf_test = realdf_test.merge(avg_real_2_test, how='inner', on='hadm_id')\n",
    "realdf_test['gcs_e'] = realdf_test['gcs_e'].fillna(4)\n",
    "realdf_test['gcs_v'] = realdf_test['gcs_v'].fillna(5)\n",
    "realdf_test['gcs_m'] = realdf_test['gcs_m'].fillna(6)\n",
    "realdf_test['gcs_total'] = realdf_test.gcs_e+realdf_test.gcs_m+realdf_test.gcs_v\n",
    "\n",
    "#merged training dataset is readldf_train\n",
    "#merged testing dataset is realdf_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['icustay_id', 'hadm_id', 'subject_id', 'dbsource', 'first_careunit',\n",
    "       'last_careunit', 'first_wardid', 'last_wardid', 'intime', 'outtime',\n",
    "       'admittime', 'dischtime', 'deathtime','admission_location', 'discharge_location','edregtime', 'edouttime',\n",
    "       'diagnosis', 'hospital_expire_flag', 'has_chartevents_data','died',\n",
    "       'dob', 'dod', 'dod_hosp', 'dod_ssn', 'expire_flag', 'ser_ind','age_at_death','los_total']\n",
    "\n",
    "realdf_train = realdf_train.drop(drop_list, axis=1)\n",
    "realdf_test = realdf_test.drop(drop_list, axis=1)\n",
    "realdf_train = realdf_train.fillna(realdf_train.median())\n",
    "realdf_test = realdf_test.fillna(realdf_test.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_list=['admission_type','insurance','language','religion','marital_status','ethnicity']\n",
    "realdf_train = pd.get_dummies(realdf_train, columns=dummies_list)      \n",
    "realdf_test = pd.get_dummies(realdf_test, columns=dummies_list)      \n",
    "\n",
    "#ensures the test set has the same dummies as the train set\n",
    "missing_cols = set(realdf_train.columns) - set(realdf_test.columns)\n",
    "for c in missing_cols:\n",
    "    realdf_test[c] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "X_train = realdf_train.drop('died_inhouse',axis=1).values\n",
    "y_train = realdf_train[['died_inhouse']].values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "X_test = realdf_test.drop('died_inhouse',axis=1).values\n",
    "y_test= realdf_test[['died_inhouse']].values.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299.2012767791748\n"
     ]
    }
   ],
   "source": [
    "t=time()\n",
    "clf = LogisticRegression(random_state=0, solver='saga', max_iter=1000000).fit(X_train, y_train)\n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.913422597709613"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.901590300740041"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisquare(realdf_train['died'].values,realdf_test['died'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train['died'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_new)",
   "language": "python",
   "name": "conda_pytorch_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
